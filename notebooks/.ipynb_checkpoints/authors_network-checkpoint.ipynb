{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "from Utils import *\n",
    "from warnings import warn\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$p(e_a|u_i)=\\frac{\\text{# posts by }u_i\\text{ in } e_a}{\\text{# posts by } u_i}$$\n",
    "\n",
    "<br>\n",
    "\n",
    "$$p(u_i|e_a)=\\frac{\\text{# posts by }u_i\\text{ in } e_a}{\\text{# posts in } e_a}$$\n",
    "\n",
    "<br>\n",
    "\n",
    "$$\\textbf{MLE Similarity}=p(u_i|u_j) = 1-\\prod_{\\forall u_i, u_j \\in users, \\forall e \\in elements} (1-\n",
    "p(e|u_j)p(u_i|e))$$\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "$$E(u) = \\text{# links by user }u$$\n",
    "<br>\n",
    "$$\\textbf{Jaccard Similarity}=J(u_i|u_j) = \\frac{E(u_i) \\cap E(u_j)}{E(u_i) \\cup E(u_j)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_users_similarity(filename, max_size=1e4):\n",
    "    users_ids = dict()  # {user: id}\n",
    "    \n",
    "    links_authors = dict()  # {link: {user: number of posts in that link by that user}}\n",
    "        \n",
    "    users_posts_counts = dict()  # {user: number of posts}\n",
    "    users_sentiments = dict()  #{user: [sum polarity, sum subjectivity]}\n",
    "    \n",
    "    mle_similarities = dict()  # {e: mle similarity}\n",
    "    jaccard_similarities = dict()  # {e:jaccard similarity}\n",
    "    \n",
    "    with open(filename) as f:\n",
    "        for i, l in enumerate(f):\n",
    "            comment = json.loads(l)\n",
    "            author = comment[\"author\"]\n",
    "            link = comment[\"link_id\"]\n",
    "#             sent = sentiment(comment[\"body\"])\n",
    "\n",
    "            users_ids.setdefault(author, len(users_ids))\n",
    "            user = users_ids[author]\n",
    "            \n",
    "            users_posts_counts.setdefault(user, 0)\n",
    "            users_posts_counts[user] += 1\n",
    "            \n",
    "            links_authors.setdefault(link, dict())\n",
    "            links_authors[link].setdefault(user, 0)\n",
    "            links_authors[link][user] += 1\n",
    "            \n",
    "#             users_sentiments.setdefault(user, [0., 0.])\n",
    "#             users_sentiments[user][0] += sent.polarity\n",
    "#             users_sentiments[user][1] += sent.subjectivity\n",
    "            \n",
    "            if i+1 == max_size: break\n",
    "        \n",
    "        for link, users in links_authors.items():\n",
    "            for u1, e_u1 in users.items():\n",
    "                for u2, u2_e in users.items():\n",
    "                    if u1 == u2: continue\n",
    "                    p_e_u1 = float(e_u1) / users_posts_counts[u1]\n",
    "                    p_u2_e = float(u2_e) / sum(users.values())\n",
    "                    \n",
    "                    \n",
    "                    mle_similarities.setdefault((u1, u2), 1)\n",
    "                    mle_similarities[(u1, u2)] *= (1-p_e_u1*p_u2_e)\n",
    "                    \n",
    "                    e = tuple(sorted((u1, u2)))\n",
    "                    jaccard_similarities.setdefault(e, 0)\n",
    "                    jaccard_similarities[e] += 1\n",
    "                    \n",
    "        for e, w in jaccard_similarities.items():\n",
    "            u1, u2 = e\n",
    "            union = len([l for l, users in links_authors.items() if u1 in users or u2 in users])\n",
    "            jaccard_similarities[e] = (w, union)\n",
    "\n",
    "        warn(\"Similarities are not normalized. Make sure to normalize MLE as 1-Sm, and Jaccard as Sj/Union\")\n",
    "        return mle_similarities, jaccard_similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_mle_network(mle_similarities, threshold=0.3, normalize=True):\n",
    "    g = nx.Graph()\n",
    "    for (u1, u2), p in mle_similarities.items():\n",
    "        sim = 1 - p if normalize else p\n",
    "        if sim < threshold: continue\n",
    "            \n",
    "        g.add_edge(u1, u2, w=sim)\n",
    "        \n",
    "    print(\"{0} nodes\".format(len(g.nodes)))\n",
    "    print(\"{0} edges\".format(len(g.edges)))\n",
    "    return g\n",
    "\n",
    "def construct_jaccard_network(jaccard_similarities, threshold=3):\n",
    "    g = nx.Graph()\n",
    "    for (u1, u2), w in jaccard_similarities.items():\n",
    "        try:\n",
    "            w, union_counts = w\n",
    "            sim = float(w) / union_counts\n",
    "        except TypeError:\n",
    "            sim = w\n",
    "            \n",
    "        if w < threshold: continue\n",
    "        \n",
    "        g.add_edge(u1, u2, w=sim)\n",
    "\n",
    "    print(\"{0} nodes\".format(len(g.nodes)))\n",
    "    print(\"{0} edges\".format(len(g.edges)))\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:55: UserWarning: Similarities are not normalized. Make sure to normalize MLE as 1-Sm, and Jaccard as Sj/Union\n"
     ]
    }
   ],
   "source": [
    "max_size = 1e4\n",
    "filename = \"../data/RC_2013-02\"\n",
    "mle_similarities, jaccard_similarities = get_users_similarity(filename, max_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLE-based Network\n",
      "1888 nodes\n",
      "1447 edges\n"
     ]
    }
   ],
   "source": [
    "print(\"MLE-based Network\")\n",
    "mle_g = construct_mle_network(mle_similarities, 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jaccard-based Network\n",
      "127 nodes\n",
      "142 edges\n"
     ]
    }
   ],
   "source": [
    "print(\"Jaccard-based Network\")\n",
    "jac_g = construct_jaccard_network(jaccard_similarities, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def component2graph(component, graph):\n",
    "    comp_graph = graph.copy()\n",
    "    for node in graph.nodes:\n",
    "        if node not in component:\n",
    "            comp_graph.remove_node(node)\n",
    "    \n",
    "    comp_nodes_count = len(comp_graph.nodes)\n",
    "    comp_edges_count = len(comp_graph.edges)\n",
    "    \n",
    "    nodes_coverage = round(100.*comp_nodes_count/len(graph.nodes()), 2)\n",
    "    edges_coverage = round(100.*comp_edges_count/len(graph.edges()), 2)\n",
    "    \n",
    "    print(\"{0} ({1}%) nodes\\t\\t{2} ({3}%) edges\".format(\n",
    "        comp_nodes_count, nodes_coverage,\n",
    "        comp_edges_count, edges_coverage,\n",
    "                                                     ))\n",
    "    return comp_graph\n",
    "\n",
    "def get_biggest_component(graph, print_first_k=5):\n",
    "    components = sorted([subG for subG in nx.connected_components(graph)], key=lambda x: len(x), reverse=True)\n",
    "    print(\"There are {0} components\".format(len(components)))\n",
    "    for i, c in enumerate(components[:print_first_k]):\n",
    "        if i == 0:\n",
    "            cg = component2graph(c, graph)\n",
    "        else:\n",
    "            component2graph(c, graph)\n",
    "    return cg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 573 components\n",
      "509 (26.96%) nodes\t\t551 (38.08%) edges\n",
      "7 (0.37%) nodes\t\t6 (0.41%) edges\n",
      "7 (0.37%) nodes\t\t6 (0.41%) edges\n",
      "6 (0.32%) nodes\t\t5 (0.35%) edges\n",
      "6 (0.32%) nodes\t\t5 (0.35%) edges\n"
     ]
    }
   ],
   "source": [
    "mle_G = get_biggest_component(mle_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 4 components\n",
      "121 (95.28%) nodes\t\t139 (97.89%) edges\n",
      "2 (1.57%) nodes\t\t1 (0.7%) edges\n",
      "2 (1.57%) nodes\t\t1 (0.7%) edges\n",
      "2 (1.57%) nodes\t\t1 (0.7%) edges\n"
     ]
    }
   ],
   "source": [
    "jac_G = get_biggest_component(jac_g)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
